{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0b98f6",
   "metadata": {},
   "source": [
    "Scikit-learn is an open source Python library that\n",
    " implements a range of \n",
    "machine learning,\n",
    " preprocessing, cross-validation and visualization algorithms using a unified interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eda3ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "adadae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # setting ignore as a parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "433f1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d11f060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = iris.data[:, :2], iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c1f0234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "867cd440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (112, 2) (112,)\n",
      "Testing set shape: (38, 2) (38,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4c06a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9001ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5a0eda0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b261c435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7418fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e0f31852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c39122a",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "78eb51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((10,5))\n",
    "y = np.array(['M','M','F','F','M','F','M','M','F','F','F'])\n",
    "X[X < 0.7] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "47cdc432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.73712142, 0.        , 0.        , 0.        , 0.83619419],\n",
       "       [0.        , 0.        , 0.86571997, 0.        , 0.7491379 ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.88651229],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.87451975, 0.        , 0.        ],\n",
       "       [0.91054666, 0.        , 0.        , 0.        , 0.97018693]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1a764aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'M', 'F', 'F', 'M', 'F', 'M', 'M', 'F', 'F', 'F'], dtype='<U1')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84284fc3",
   "metadata": {},
   "source": [
    "## Preprocessing the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37d64b",
   "metadata": {},
   "source": [
    "### Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1f4d5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "standardized_X = scaler.transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793a626",
   "metadata": {},
   "source": [
    "- Standardize - Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "- transform -Perform standardization by centering and scaling.\n",
    "- Scaling - Scaling is a preprocessing step in machine learning that involves transforming the input features so that they have the same scale or distribution. This is important because many machine learning algorithms assume that all features are on the same scale, and that the scale of the features does not affect their importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba26171",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "- Normalization is the process of scaling individual samples to have unit norm. This process can be useful if you plan to use a quadratic form such as the dot-product or any other kernel to quantify the similarity of any pair of samples.\n",
    "\n",
    "This assumption is the base of the Vector Space Model often used in text classification and clustering contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "92a3a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer().fit(X_train)\n",
    "normalized_X = scaler.transform(X_train)\n",
    "normalized_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c5dfd",
   "metadata": {},
   "source": [
    "### Binarization\n",
    "- Feature binarization is the process of thresholding numerical features to get boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ab44aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binary_X = binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffabc64",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features\n",
    "- Often features are not given as continuous values but categorical. For example a person could have features [\"male\", \"female\"], [\"from Europe\", \"from US\", \"from Asia\"], [\"uses Firefox\", \"uses Chrome\", \"uses Safari\", \"uses Internet Explorer\"]. Such features can be efficiently coded as integers, for instance [\"male\", \"from US\", \"uses Internet Explorer\"] could be expressed as [0, 1, 3] while [\"female\", \"from Asia\", \"uses Chrome\"] would be [1, 2, 1].\n",
    "\n",
    "- To convert categorical features to such integer codes, we can use the OrdinalEncoder. This estimator transforms each categorical feature to one new feature of integers (0 to n_categories - 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8cb72561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b0c71",
   "metadata": {},
   "source": [
    "### imputing Missing Values \n",
    "- The SimpleImputer class provides basic strategies for imputing missing values. Missing values can be imputed with a provided constant value, or using the statistics (mean, median or most frequent) of each column in which the missing values are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "dd136849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.91090798, -1.59775374],\n",
       "       [-1.0271058 ,  0.08448757],\n",
       "       [ 0.59966379, -1.59775374],\n",
       "       [ 0.01867465, -0.96691325],\n",
       "       [ 0.48346596, -0.33607276],\n",
       "       [-1.25950146,  0.29476773],\n",
       "       [-1.37569929,  0.71532806],\n",
       "       [-0.79471015, -1.17719341],\n",
       "       [-1.14330363,  0.71532806],\n",
       "       [ 2.45882905,  1.55644871],\n",
       "       [-0.79471015,  0.71532806],\n",
       "       [-0.79471015,  1.34616854],\n",
       "       [-0.21372101, -0.33607276],\n",
       "       [ 0.83205945, -0.1257926 ],\n",
       "       [-0.44611666,  1.76672887],\n",
       "       [ 1.41304859,  0.29476773],\n",
       "       [ 0.01867465, -0.54635292],\n",
       "       [ 2.22643339, -0.96691325],\n",
       "       [-0.32991883, -1.17719341],\n",
       "       [ 0.13487248,  0.29476773],\n",
       "       [-1.0271058 ,  1.13588838],\n",
       "       [-1.49189712, -1.59775374],\n",
       "       [ 0.59966379, -0.54635292],\n",
       "       [-1.60809495, -0.33607276],\n",
       "       [-0.91090798,  1.13588838],\n",
       "       [ 1.64544425, -0.1257926 ],\n",
       "       [ 0.25107031,  0.71532806],\n",
       "       [ 0.48346596, -1.8080339 ],\n",
       "       [ 1.8778399 , -0.54635292],\n",
       "       [ 1.18065293, -0.1257926 ],\n",
       "       [ 0.71586162, -0.54635292],\n",
       "       [-0.09752318, -1.17719341],\n",
       "       [-0.91090798,  0.92560822],\n",
       "       [-0.79471015,  1.55644871],\n",
       "       [ 1.18065293, -0.54635292],\n",
       "       [-0.67851232, -0.75663309],\n",
       "       [-0.79471015,  1.55644871],\n",
       "       [-0.21372101, -1.17719341],\n",
       "       [ 0.36726814, -0.1257926 ],\n",
       "       [ 0.94825728, -0.33607276],\n",
       "       [ 0.71586162, -0.54635292],\n",
       "       [-1.72429277, -0.1257926 ],\n",
       "       [ 1.64544425,  1.13588838],\n",
       "       [-0.79471015,  0.92560822],\n",
       "       [ 0.59966379, -1.17719341],\n",
       "       [-1.60809495,  0.29476773],\n",
       "       [ 2.11023556, -0.1257926 ],\n",
       "       [ 0.71586162,  0.29476773],\n",
       "       [-0.79471015,  1.55644871],\n",
       "       [ 0.83205945,  0.29476773],\n",
       "       [ 0.59966379, -0.75663309],\n",
       "       [-0.91090798,  0.92560822],\n",
       "       [-0.67851232,  0.71532806],\n",
       "       [ 0.71586162, -0.75663309],\n",
       "       [ 0.01867465,  1.97700903],\n",
       "       [-0.09752318,  2.81812969],\n",
       "       [-1.37569929,  0.29476773],\n",
       "       [ 1.29685076,  0.08448757],\n",
       "       [ 0.59966379, -0.33607276],\n",
       "       [-0.32991883,  0.92560822],\n",
       "       [-0.09752318, -0.96691325],\n",
       "       [-0.91090798,  0.50504789],\n",
       "       [ 0.25107031, -1.8080339 ],\n",
       "       [-1.0271058 , -0.1257926 ],\n",
       "       [-0.91090798, -2.22859423],\n",
       "       [ 0.94825728, -0.1257926 ],\n",
       "       [-0.09752318, -0.54635292],\n",
       "       [-0.32991883, -0.96691325],\n",
       "       [-0.32991883, -1.59775374],\n",
       "       [-1.14330363,  0.08448757],\n",
       "       [ 0.25107031, -0.33607276],\n",
       "       [-0.91090798, -0.1257926 ],\n",
       "       [ 1.29685076,  0.08448757],\n",
       "       [ 1.06445511, -1.17719341],\n",
       "       [-0.56231449,  1.34616854],\n",
       "       [-0.67851232,  2.1872892 ],\n",
       "       [-0.91090798,  0.71532806],\n",
       "       [-1.37569929,  1.13588838],\n",
       "       [ 2.22643339,  1.55644871],\n",
       "       [ 1.76164208, -0.33607276],\n",
       "       [-1.37569929,  0.08448757],\n",
       "       [-0.32991883, -1.38747358],\n",
       "       [ 0.01867465, -0.75663309],\n",
       "       [ 1.06445511,  0.50504789],\n",
       "       [ 0.01867465, -0.75663309],\n",
       "       [-0.44611666,  1.34616854],\n",
       "       [-0.91090798,  0.71532806],\n",
       "       [ 0.25107031, -0.75663309],\n",
       "       [-0.09752318, -0.54635292],\n",
       "       [ 0.36726814, -0.54635292],\n",
       "       [-0.79471015,  0.50504789],\n",
       "       [-0.21372101, -0.1257926 ],\n",
       "       [-0.44611666, -0.1257926 ],\n",
       "       [-0.44611666,  1.76672887],\n",
       "       [ 1.06445511,  0.50504789],\n",
       "       [-1.0271058 , -1.17719341],\n",
       "       [ 0.48346596,  0.71532806],\n",
       "       [-0.32991883, -1.38747358],\n",
       "       [ 2.22643339, -0.54635292],\n",
       "       [-0.44611666,  0.71532806],\n",
       "       [ 1.06445511, -0.1257926 ],\n",
       "       [-0.32991883,  2.39756936],\n",
       "       [-0.91090798,  0.29476773],\n",
       "       [-1.14330363, -0.1257926 ],\n",
       "       [ 0.01867465, -0.75663309],\n",
       "       [ 0.13487248, -0.1257926 ],\n",
       "       [ 1.52924642, -0.1257926 ],\n",
       "       [-1.0271058 , -1.38747358],\n",
       "       [ 0.59966379, -1.17719341],\n",
       "       [-0.21372101, -0.1257926 ],\n",
       "       [ 2.22643339, -0.1257926 ],\n",
       "       [-0.44611666,  0.71532806]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=0, strategy='mean')\n",
    "imp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3312b2cf",
   "metadata": {},
   "source": [
    "### Generating Polynomial Features\n",
    "- Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "778e0863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 5.10000000e+00, 3.50000000e+00, ...,\n",
       "        1.11517875e+03, 7.65318750e+02, 5.25218750e+02],\n",
       "       [1.00000000e+00, 4.90000000e+00, 3.00000000e+00, ...,\n",
       "        6.48270000e+02, 3.96900000e+02, 2.43000000e+02],\n",
       "       [1.00000000e+00, 4.70000000e+00, 3.20000000e+00, ...,\n",
       "        7.23845120e+02, 4.92830720e+02, 3.35544320e+02],\n",
       "       ...,\n",
       "       [1.00000000e+00, 6.50000000e+00, 3.00000000e+00, ...,\n",
       "        1.14075000e+03, 5.26500000e+02, 2.43000000e+02],\n",
       "       [1.00000000e+00, 6.20000000e+00, 3.40000000e+00, ...,\n",
       "        1.51084576e+03, 8.28528320e+02, 4.54354240e+02],\n",
       "       [1.00000000e+00, 5.90000000e+00, 3.00000000e+00, ...,\n",
       "        9.39870000e+02, 4.77900000e+02, 2.43000000e+02]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(5)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef492fb4",
   "metadata": {},
   "source": [
    "### Training And Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6a92bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac3116",
   "metadata": {},
   "source": [
    "# Create Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "16f049a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised \n",
    "# Linear regression \n",
    "\n",
    "from sklearn.linear_model  import LinearRegression \n",
    "lr= LinearRegression(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "992b0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines (SVM)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6106202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3be31203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN \n",
    "\n",
    "from sklearn import neighbors\n",
    "knn=neighbors.KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d8c8198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unsupervised \n",
    "#Principal Component analysis (PCA) \n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "pca= PCA(n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0c46f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K Means\n",
    "from sklearn.cluster import KMeans \n",
    "k_means = KMeans ( n_clusters=3, random_state =0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e5521",
   "metadata": {},
   "source": [
    "## Model Fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ee0d829c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supervised\n",
    "\n",
    "lr.fit(X,y)\n",
    "knn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5d284ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unsupervised\n",
    "\n",
    "k_means.fit(X_train)\n",
    "pca_model = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb0c4d",
   "metadata": {},
   "source": [
    "Principal Component Analysis is an unsupervised learning algorithm that is used for the dimensionality reduction in machine learning. It is a statistical process that converts the observations of correlated features into a set of linearly uncorrelated features with the help of orthogonal transformation. These new transformed features are called the Principal Components. It is one of the popular tools that is used for exploratory data analysis and predictive modeling. It is a technique to draw strong patterns from the given dataset by reducing the variances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381026e",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3d170046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9f3c358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = svc.predict(np.random.random((2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1f3075c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f066ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "2bfbaecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unsupervised estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "705b6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =k_means.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6649df",
   "metadata": {},
   "source": [
    "## evaluate model's performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ec0059d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c94dc3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "16316d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a3ef60dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c5f9ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.25      0.36      0.30        11\n",
      "           2       0.50      0.37      0.42        19\n",
      "\n",
      "    accuracy                           0.50        38\n",
      "   macro avg       0.58      0.58      0.57        38\n",
      "weighted avg       0.53      0.50      0.51        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report \n",
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e694c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0  0]\n",
      " [ 0  4  7]\n",
      " [ 0 12  7]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06cf27a",
   "metadata": {},
   "source": [
    "## regression Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e953b8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean absolute error \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_true = [3, -0.5, 2]\n",
    "y_pred = [2.5, 0.0, 2]\n",
    "mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a36306bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean squared error \n",
    " \n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "538e01bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R2 score\n",
    "# R2 is a measure of the goodness of fit of a model. \n",
    "# In regression, the R2 coefficient of determination is a statistical measure \n",
    "# of how well the regression predictions approximate the real data points. \n",
    "# An R2 of 1 indicates that the regression predictions perfectly fit the data.\n",
    "\n",
    "from sklearn.metrics import r2_score \n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9641c01",
   "metadata": {},
   "source": [
    "## Clustering Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a7d67360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusted Rand Index\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "adjusted_rand_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "98ff1475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Homogeneity\n",
    "\n",
    "from sklearn.metrics import homogeneity_score\n",
    "homogeneity_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "32456818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V-measure\n",
    "\n",
    "from sklearn.metrics import v_measure_score\n",
    "v_measure_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeef43b",
   "metadata": {},
   "source": [
    "## Cross-validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9ebbec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85714286 0.75       0.85714286 0.89285714]\n",
      "[-4.31567384 -1.89773191]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(knn, X_train, y_train, cv=4))\n",
    "print(cross_val_score(lr, X, y, cv=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec66644",
   "metadata": {},
   "source": [
    "## Tune your model \n",
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ca75fa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8126482213438736\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\"n_neighbors\": np.arange(1,3), \"metric\": [\"euclidean\", \"cityblock\"]}\n",
    "grid = GridSearchCV(estimator=knn,param_grid=params)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c4966a",
   "metadata": {},
   "source": [
    "#### Randomized Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "37d9e3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8392857142857142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {\"n_neighbors\": range(1,5), \"weights\": [\"uniform\", \"distance\"]}\n",
    "rsearch = RandomizedSearchCV(estimator=knn,\n",
    "   param_distributions=params,\n",
    "   cv=4,\n",
    "   n_iter=8,\n",
    "   random_state=5)\n",
    "rsearch.fit(X_train, y_train)\n",
    "print(rsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b2b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
